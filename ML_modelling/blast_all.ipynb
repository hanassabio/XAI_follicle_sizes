{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z1WUNkwevZp2",
    "ExecuteTime": {
     "start_time": "2024-06-20T21:08:44.206641Z",
     "end_time": "2024-06-20T21:08:44.604699Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.int = int\n",
    "np.bool = bool\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from skopt import BayesSearchCV\n",
    "import gc\n",
    "from sklearn.metrics import mean_absolute_error, max_error, mean_absolute_percentage_error, mean_squared_error, r2_score, median_absolute_error\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "P9R9QMSevsWV",
    "ExecuteTime": {
     "start_time": "2024-06-20T21:10:55.453745Z",
     "end_time": "2024-06-20T21:12:39.879602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 138)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scans=pd.read_excel(\"../dummy_data.xlsx\")\n",
    "print(scans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "carbon = scans.copy()\n",
    "carbon['protocol_map'] = carbon['protocol_map'].str.upper()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-27T17:37:10.342224Z",
     "end_time": "2024-06-27T17:37:10.411769Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 138)\n"
     ]
    }
   ],
   "source": [
    "carbon = carbon[carbon['No. Suitable Blastocysts']>-1]\n",
    "\n",
    "print(carbon.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-27T17:37:18.884277Z",
     "end_time": "2024-06-27T17:37:18.941914Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 135)\n"
     ]
    }
   ],
   "source": [
    "carbon = carbon[~(pd.isna(carbon['DoT Follicles']))]\n",
    "print(carbon.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-27T17:37:20.963987Z",
     "end_time": "2024-06-27T17:37:20.993040Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Clinic\nUK1    50\nUK2    50\nUK3    50\nUK4    50\nUK5    50\nUK6    50\nUK7    50\nUK8    50\nUK9    50\nP1     50\nP2     50\nName: count, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carbon['Clinic'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-27T17:37:29.574907Z",
     "end_time": "2024-06-27T17:37:29.585482Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "#create dataset\n",
    "X = carbon[['6_mm', '7_mm', '8_mm', '9_mm','10_mm','11_mm','12_mm','13_mm','14_mm','15_mm','16_mm','17_mm','18_mm','19_mm','20_mm','21_mm','22_mm','23_mm','24_mm','25_mm','26_mm']]\n",
    "\n",
    "y = carbon[['No. Suitable Blastocysts']]\n",
    "y=y.values.ravel()\n",
    "\n",
    "y = np.log(y+1)\n",
    "\n",
    "by_clinic = carbon['Clinic']\n",
    "by_clinic = by_clinic.values.ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-27T17:37:32.935780Z",
     "end_time": "2024-06-27T17:37:32.967876Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(550, 21)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-24T18:06:53.719627Z",
     "end_time": "2024-06-24T18:06:53.763223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(550,)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-24T14:22:09.366106Z",
     "end_time": "2024-06-24T14:22:09.376930Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(550,)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_clinic.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-03T14:33:24.853818Z",
     "end_time": "2024-05-03T14:33:24.874487Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 21)\n",
      "(500,)\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 51\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28mprint\u001B[39m(y_train\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     39\u001B[0m bayes_opt \u001B[38;5;241m=\u001B[39m BayesSearchCV(\n\u001B[0;32m     40\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mrf,\n\u001B[0;32m     41\u001B[0m     search_spaces\u001B[38;5;241m=\u001B[39mparam_grid,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     49\u001B[0m     return_train_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     50\u001B[0m )\n\u001B[1;32m---> 51\u001B[0m \u001B[43mbayes_opt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclinic_train\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m##added groups here\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;66;03m# Get the best parameters and the corresponding model\u001B[39;00m\n\u001B[0;32m     54\u001B[0m best_params \u001B[38;5;241m=\u001B[39m bayes_opt\u001B[38;5;241m.\u001B[39mbest_params_\n",
      "File \u001B[1;32m~\\OneDrive - Imperial College London\\PhD\\TFP_Follicle_Sizes\\venv\\Lib\\site-packages\\skopt\\searchcv.py:466\u001B[0m, in \u001B[0;36mBayesSearchCV.fit\u001B[1;34m(self, X, y, groups, callback, **fit_params)\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    464\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_kwargs_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_kwargs)\n\u001B[1;32m--> 466\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;66;03m# BaseSearchCV never ranked train scores,\u001B[39;00m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;66;03m# but apparently we used to ship this (back-compat)\u001B[39;00m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_train_score:\n",
      "File \u001B[1;32m~\\OneDrive - Imperial College London\\PhD\\TFP_Follicle_Sizes\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    868\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    869\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    870\u001B[0m     )\n\u001B[0;32m    872\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 874\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    878\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\OneDrive - Imperial College London\\PhD\\TFP_Follicle_Sizes\\venv\\Lib\\site-packages\\skopt\\searchcv.py:512\u001B[0m, in \u001B[0;36mBayesSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m n_iter \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    509\u001B[0m     \u001B[38;5;66;03m# when n_iter < n_points points left for evaluation\u001B[39;00m\n\u001B[0;32m    510\u001B[0m     n_points_adjusted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(n_iter, n_points)\n\u001B[1;32m--> 512\u001B[0m     optim_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    513\u001B[0m \u001B[43m        \u001B[49m\u001B[43msearch_space\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    514\u001B[0m \u001B[43m        \u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_points\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_points_adjusted\u001B[49m\n\u001B[0;32m    515\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    516\u001B[0m     n_iter \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m n_points\n\u001B[0;32m    518\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001B[1;32m~\\OneDrive - Imperial College London\\PhD\\TFP_Follicle_Sizes\\venv\\Lib\\site-packages\\skopt\\searchcv.py:408\u001B[0m, in \u001B[0;36mBayesSearchCV._step\u001B[1;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001B[0m\n\u001B[0;32m    405\u001B[0m \u001B[38;5;66;03m# make lists into dictionaries\u001B[39;00m\n\u001B[0;32m    406\u001B[0m params_dict \u001B[38;5;241m=\u001B[39m [point_asdict(search_space, p) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m params]\n\u001B[1;32m--> 408\u001B[0m all_results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;66;03m# Feed the point and objective value back into optimizer\u001B[39;00m\n\u001B[0;32m    410\u001B[0m \u001B[38;5;66;03m# Optimizer minimizes objective, hence provide negative score\u001B[39;00m\n\u001B[0;32m    411\u001B[0m local_results \u001B[38;5;241m=\u001B[39m all_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean_test_score\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(params):]\n",
      "File \u001B[1;32m~\\OneDrive - Imperial College London\\PhD\\TFP_Follicle_Sizes\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    814\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    815\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    817\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    818\u001B[0m         )\n\u001B[0;32m    819\u001B[0m     )\n\u001B[1;32m--> 821\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    822\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    823\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    832\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    834\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    835\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    836\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    838\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    839\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    843\u001B[0m     )\n",
      "File \u001B[1;32m~\\OneDrive - Imperial College London\\PhD\\TFP_Follicle_Sizes\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     62\u001B[0m )\n\u001B[1;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive - Imperial College London\\PhD\\TFP_Follicle_Sizes\\venv\\Lib\\site-packages\\joblib\\parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1098\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[1;32m~\\OneDrive - Imperial College London\\PhD\\TFP_Follicle_Sizes\\venv\\Lib\\site-packages\\joblib\\parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    974\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 975\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    976\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    977\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[1;32m~\\OneDrive - Imperial College London\\PhD\\TFP_Follicle_Sizes\\venv\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    564\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[0;32m    565\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[0;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:451\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m    449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[1;32m--> 451\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[0;32m    454\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'max_iter': (500, 5000),\n",
    "    'learning_rate': (0.0001, 0.1),\n",
    "    'l2_regularization': (0.0, 1.0),\n",
    "    'min_samples_leaf': (5, 20),\n",
    "    'loss': ('squared_error', 'absolute_error', 'poisson')\n",
    "}\n",
    "\n",
    "outer_cv = LeaveOneGroupOut()\n",
    "outer_cv.get_n_splits(X, y, by_clinic)\n",
    "splits = outer_cv.get_n_splits(groups=by_clinic)\n",
    "\n",
    "# Initialize arrays to store the results\n",
    "outer_scores = []\n",
    "best_params_list = pd.DataFrame(index=param_grid)\n",
    "inner_results = []\n",
    "df_perm_importance = pd.DataFrame(index=X.columns)\n",
    "\n",
    "shap_values_per_fold = []\n",
    "explanation_per_fold = []\n",
    "interactions_per_fold = []\n",
    "\n",
    "pred_vals = pd.DataFrame(columns=['Clinic', 'actual', 'pred'])\n",
    "\n",
    "# Perform nested cross-validation\n",
    "for i, (train_index, test_index) in enumerate(outer_cv.split(X, y, by_clinic)):\n",
    "    # Check the indices\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clinic_train, clinic_test = by_clinic[train_index], by_clinic[test_index]\n",
    "\n",
    "    rf = HistGradientBoostingRegressor()\n",
    "\n",
    "    inner_cv = LeaveOneGroupOut()\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    bayes_opt = BayesSearchCV(\n",
    "        estimator=rf,\n",
    "        search_spaces=param_grid,\n",
    "        n_iter=30,\n",
    "        n_points=5,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=inner_cv,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        verbose=1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    bayes_opt.fit(X=X_train, y=y_train, groups=clinic_train)  ##added groups here\n",
    "\n",
    "    # Get the best parameters and the corresponding model\n",
    "    best_params = bayes_opt.best_params_\n",
    "    best_model = bayes_opt.best_estimator_\n",
    "\n",
    "    # Store the best parameters\n",
    "    best_params_list[f'best_params_run_{i}'] = best_params\n",
    "    print(f\"best inner score_{i}:\", bayes_opt.best_score_)\n",
    "    # Store the results of each fold of the inner cross-validation\n",
    "    inner_results.append(pd.DataFrame(bayes_opt.cv_results_))\n",
    "\n",
    "    # Evaluate the best model on the outer test fold\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    y_pred = np.exp(y_pred) - 1\n",
    "\n",
    "    ##same exp for y_test\n",
    "    y_test = np.exp(y_test) - 1\n",
    "\n",
    "    # Append predictions and actual values to pred_vals\n",
    "    temp_df = pd.DataFrame({'Clinic': clinic_test, 'actual': y_test, 'pred': y_pred})\n",
    "    pred_vals = pd.concat([pred_vals, temp_df], ignore_index=True)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f'mae_{i}', mae)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    medae = median_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    max_er = max_error(y_test, y_pred)\n",
    "    outer_scores.append([mae, r2, medae, mape, rmse, max_er])\n",
    "\n",
    "    # Perform permutation importance on the outer test fold\n",
    "    perm_result = permutation_importance(best_model, X_test, y_test, n_repeats=5)\n",
    "\n",
    "    # Append mean and std of each run to the DataFrame for the current outer fold\n",
    "    df_perm_importance[f'mean_run_{i}'] = perm_result.importances_mean\n",
    "    df_perm_importance[f'std_run_{i}'] = perm_result.importances_std\n",
    "\n",
    "# Calculate average of means across each row\n",
    "df_perm_importance['final_mean'] = df_perm_importance.filter(regex=r'^mean_run_\\d+$').mean(axis=1)\n",
    "\n",
    "# Calculate average of standard deviations across each row\n",
    "df_perm_importance['final_sd'] = np.sqrt(df_perm_importance.filter(regex=r'^std_run_\\d+$').pow(2).mean(axis=1))\n",
    "\n",
    "# Concatenate the inner_results DataFrames\n",
    "inner_results_df = pd.concat(inner_results)\n",
    "\n",
    "column_names = ['MAE', 'R2', 'MedAE', 'MAPE', 'RMSE', 'Max Error']\n",
    "outer_scores_df = pd.DataFrame(outer_scores, columns=column_names)\n",
    "print(\"development done\")\n",
    "\n",
    "mae_values = [score[0] for score in outer_scores]\n",
    "r2_values = [score[1] for score in outer_scores]\n",
    "medae_values = [score[2] for score in outer_scores]\n",
    "mape_values = [score[3] for score in outer_scores]\n",
    "rmse_values = [score[4] for score in outer_scores]\n",
    "maxerror_values = [score[5] for score in outer_scores]\n",
    "\n",
    "mae_mean = np.mean(mae_values)\n",
    "mae_std = np.std(mae_values)\n",
    "\n",
    "r2_mean = np.mean(r2_values)\n",
    "r2_std = np.std(r2_values)\n",
    "\n",
    "medae_mean = np.mean(medae_values)\n",
    "medae_std = np.std(medae_values)\n",
    "\n",
    "mape_mean = np.mean(mape_values)\n",
    "mape_std = np.std(mape_values)\n",
    "\n",
    "rmse_mean = np.mean(rmse_values)\n",
    "rmse_std = np.std(rmse_values)\n",
    "\n",
    "maxerror_mean = np.mean(maxerror_values)\n",
    "maxerror_std = np.std(maxerror_values)\n",
    "\n",
    "mae_mean = round(mae_mean, 4)\n",
    "mae_std = round(mae_std, 4)\n",
    "r2_mean = round(r2_mean, 4)\n",
    "r2_std = round(r2_std, 4)\n",
    "\n",
    "medae_mean = round(medae_mean, 4)\n",
    "medae_std = round(medae_std, 4)\n",
    "\n",
    "mape_mean = round(mape_mean, 4)\n",
    "mape_std = round(mape_std, 4)\n",
    "\n",
    "rmse_mean = round(rmse_mean, 4)\n",
    "rmse_std = round(rmse_std, 4)\n",
    "\n",
    "maxerror_mean = round(maxerror_mean, 4)\n",
    "maxerror_std = round(maxerror_std, 4)\n",
    "\n",
    "cv_averaged = {\n",
    "    'Metric': ['MAE', 'R2', 'MedAE', 'MAPE', 'RMSE', 'Max Error'],\n",
    "    'Mean': [mae_mean, r2_mean, medae_mean, mape_mean, rmse_mean, maxerror_mean],\n",
    "    'Standard Deviation': [mae_std, r2_std, medae_std, mape_std, rmse_std, maxerror_std],\n",
    "}\n",
    "\n",
    "final_cv_scores = pd.DataFrame(cv_averaged)\n",
    "\n",
    "print(\"MAE Mean:\", mae_mean)\n",
    "print(\"MAE Standard Deviation:\", mae_std)\n",
    "print(\"R2 Mean:\", r2_mean)\n",
    "print(\"R2 Standard Deviation:\", r2_std)\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a folder in the current directory\n",
    "folder_name = \"BLAST\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "model_name = \"BLAST_ALL\"\n",
    "# Get the current date in UK date format (DD-MM-YYYY)\n",
    "current_date = datetime.now().strftime(\"%d-%m-%Y %H-%M\")\n",
    "\n",
    "# Save the DataFrames to CSV files\n",
    "csv_file_paths = {\n",
    "    \"Importances\": df_perm_importance,\n",
    "    \"Metrics\": final_cv_scores,\n",
    "    \"BestParams\": best_params_list,\n",
    "    \"InnerRuns\": inner_results_df,\n",
    "    \"OuterScores\": outer_scores_df,\n",
    "    \"Predictions\": pred_vals\n",
    "}\n",
    "\n",
    "for name, df in csv_file_paths.items():\n",
    "    file_name = f\"{current_date}_HGBR_{model_name}_{name}.csv\"\n",
    "    csv_file_path = os.path.join(folder_name, file_name)\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(\"Files saved to:\", folder_name)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
